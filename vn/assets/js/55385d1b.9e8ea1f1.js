"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[214],{6182:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var r=t(4848),o=t(8453);const i={},c="Deep RL",s={id:"ReinforcementLearning/DeepRL/index",title:"Deep RL",description:"",source:"@site/docs/ReinforcementLearning/DeepRL/index.md",sourceDirName:"ReinforcementLearning/DeepRL",slug:"/ReinforcementLearning/DeepRL/",permalink:"/vn/docs/ReinforcementLearning/DeepRL/",draft:!1,unlisted:!1,editUrl:"https://github.com/nhan2892005/ResearchBlog/docs/ReinforcementLearning/DeepRL/index.md",tags:[],version:"current",frontMatter:{},sidebar:"RLsidebar",previous:{title:"Monte Carlo Methods",permalink:"/vn/docs/ReinforcementLearning/MonteCarlos/"},next:{title:"index",permalink:"/vn/docs/ReinforcementLearning/OffOnPolicy/"}},a={},d=[];function p(e){const n={h1:"h1",header:"header",...(0,o.R)(),...e.components};return(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"deep-rl",children:"Deep RL"})})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>c,x:()=>s});var r=t(6540);const o={},i=r.createContext(o);function c(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:c(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);