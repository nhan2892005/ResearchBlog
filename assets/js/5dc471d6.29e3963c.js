"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[567],{9241:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>t,default:()=>u,frontMatter:()=>i,metadata:()=>c,toc:()=>m});var o=r(4848),s=r(8453);const i={},t="Markov Decision Processes",c={id:"ReinforcementLearning/MarkovDecisionProcesses/index",title:"Markov Decision Processes",description:"",source:"@site/docs/ReinforcementLearning/MarkovDecisionProcesses/index.md",sourceDirName:"ReinforcementLearning/MarkovDecisionProcesses",slug:"/ReinforcementLearning/MarkovDecisionProcesses/",permalink:"/ResearchBlog/docs/ReinforcementLearning/MarkovDecisionProcesses/",draft:!1,unlisted:!1,editUrl:"https://github.com/nhan2892005/ResearchBlog/docs/ReinforcementLearning/MarkovDecisionProcesses/index.md",tags:[],version:"current",frontMatter:{},sidebar:"RLsidebar",previous:{title:"Reinforcement Learning",permalink:"/ResearchBlog/docs/ReinforcementLearning/Introduction/intro"},next:{title:"Dynamic Programming",permalink:"/ResearchBlog/docs/ReinforcementLearning/DynamicProgramming/"}},a={},m=[];function d(e){const n={h1:"h1",header:"header",...(0,s.R)(),...e.components};return(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"markov-decision-processes",children:"Markov Decision Processes"})})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>c});var o=r(6540);const s={},i=o.createContext(s);function t(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);