"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[722],{9098:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>s,default:()=>f,frontMatter:()=>o,metadata:()=>i,toc:()=>d});var t=r(4848),c=r(8453);const o={sidebar_position:4},s="References",i={id:"ReinforcementLearningScheduler/References",title:"References",description:"",source:"@site/docs/ReinforcementLearningScheduler/References.md",sourceDirName:"ReinforcementLearningScheduler",slug:"/ReinforcementLearningScheduler/References",permalink:"/ResearchBlog/docs/ReinforcementLearningScheduler/References",draft:!1,unlisted:!1,editUrl:"https://github.com/nhan2892005/ResearchBlog/docs/ReinforcementLearningScheduler/References.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"RLS",previous:{title:"Reinforcement Learning",permalink:"/ResearchBlog/docs/ReinforcementLearningScheduler/ReinforcementLearning"}},a={},d=[];function u(e){const n={h1:"h1",header:"header",...(0,c.R)(),...e.components};return(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"references",children:"References"})})}function f(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>i});var t=r(6540);const c={},o=t.createContext(c);function s(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);