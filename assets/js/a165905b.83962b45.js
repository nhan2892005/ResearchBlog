"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[600],{6127:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>a,toc:()=>d});var o=t(4848),r=t(8453);const i={},s="Monte Carlo Methods",a={id:"ReinforcementLearning/MonteCarlos/index",title:"Monte Carlo Methods",description:"",source:"@site/docs/ReinforcementLearning/MonteCarlos/index.md",sourceDirName:"ReinforcementLearning/MonteCarlos",slug:"/ReinforcementLearning/MonteCarlos/",permalink:"/ResearchBlog/docs/ReinforcementLearning/MonteCarlos/",draft:!1,unlisted:!1,editUrl:"https://github.com/nhan2892005/ResearchBlog/docs/ReinforcementLearning/MonteCarlos/index.md",tags:[],version:"current",frontMatter:{},sidebar:"RLsidebar",previous:{title:"Dynamic Programming",permalink:"/ResearchBlog/docs/ReinforcementLearning/DynamicProgramming/"},next:{title:"Deep RL",permalink:"/ResearchBlog/docs/ReinforcementLearning/DeepRL/"}},c={},d=[];function l(e){const n={h1:"h1",header:"header",...(0,r.R)(),...e.components};return(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"monte-carlo-methods",children:"Monte Carlo Methods"})})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>a});var o=t(6540);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);